full_censusdata <- do.call(rbind, list(LCD_census_2009,
LCD_census_2012,
LCD_census_2016,
LCD_census_2020))
View(full_censusdata)
View(DP04_2012)
# step 5 - prep for join with voting data ------------------------------------------------
full_censusdata %>%
mutate(county_fips = str_extract(GEO_ID, "(?<=US)\\d+")) %>%
mutate(unique_id = paste0(census_year, "_", county_fips)) # "YEAR_FIPS"
# step 5 - prep for join with voting data ------------------------------------------------
full_censusdata <- full_censusdata %>%
mutate(county_fips = str_extract(GEO_ID, "(?<=US)\\d+")) %>%
mutate(unique_id = paste0(census_year, "_", county_fips)) # "YEAR_FIPS"
View(full_censusdata)
full_censusdata %>%
write_csv(here("data/ACS_2009-2020_SelectedIndicators.csv"))
# libraries -------------------------------------------------------------------
# loading
library(tidyverse)
library(here)
# set directory
here::i_am("code/cleaning_votingdata.R")
# Step 1 - load data ----------------------------------------------------------------------------------
countypres_raw <- read_csv(here("data/countypres_2000-2020.csv"))
# COMMON PRE-PROCESS ----------------------------------------------------------------
# making the dataset wide
voting_as_wide <- countypres_raw %>%
pivot_wider(names_from = party,
values_from = candidatevotes) %>%
mutate(state_county = paste0(state_po,
"-",
county_name))
# dropping all vote data and retaining county identifiers for future indexing
counties_only_all <- voting_as_wide %>%
group_by(state,
state_po,
state_county,
county_name,
county_fips) %>%
summarise(placeholder = sum(county_fips)) %>% # ugly workaround
select(state,
state_po,
state_county,
county_name,
county_fips) %>% # retain only our identifier columns
filter(!(is.na(county_fips))) # drop NA fips:
# Connecticut - WRITE-IN
# Maine - Uniformed Service & Overseas
# Rhode Island - Federal Precinct
View(voting_as_wide)
# Step 3 -  Join DPs by year together ----------------------------------------------------
census_2009 <- DP02_2009 %>%
inner_join(DP03_2009, by = "GEO_ID") %>%
inner_join(DP04_2009, by = "GEO_ID") %>%
inner_join(DP05_2009, by = "GEO_ID") %>%
mutate(census_year = "2008")
census_2012 <- DP02_2012 %>%
inner_join(DP03_2012, by = "GEO_ID") %>%
inner_join(DP04_2012, by = "GEO_ID") %>%
inner_join(DP05_2012, by = "GEO_ID") %>%
mutate(census_year = "2012")
census_2016 <- DP02_2016 %>%
inner_join(DP03_2016, by = "GEO_ID") %>%
inner_join(DP04_2016, by = "GEO_ID") %>%
inner_join(DP05_2016, by = "GEO_ID") %>%
mutate(census_year = "2016")
census_2020 <- DP02_2020 %>%
inner_join(DP03_2020, by = "GEO_ID") %>%
inner_join(DP04_2020, by = "GEO_ID") %>%
inner_join(DP05_2020, by = "GEO_ID") %>%
mutate(census_year = "2020")
# Step 4 - drop all year dfs to lowest common denominator of columns ----------------------
# Step 1: Identify common columns
common_columns <- Reduce(intersect, list(names(census_2009),
names(census_2012),
names(census_2016),
names(census_2020)))
# Step 2: Subset each dataset by the common columns
# subsetting by our list means they will all be in same order
# which means we can rbind afterwards without issue
LCD_census_2009 <- census_2009[ , common_columns]
LCD_census_2012 <- census_2012[ , common_columns]
LCD_census_2016 <- census_2016[ , common_columns]
LCD_census_2020 <- census_2020[ , common_columns]
# Step 3: Row-bind the datasets
full_censusdata <- do.call(rbind, list(LCD_census_2009,
LCD_census_2012,
LCD_census_2016,
LCD_census_2020))
# MAYBE: NEED TO DROP ALSO ANY FIPS THAT ARE NOT IN EVERY YEAR?
# fuuuuuuuuuuuuuck
# skip this for now
# step 5 - prep for join with voting data ------------------------------------------------
full_censusdata <- full_censusdata %>%
mutate(county_fips = str_extract(GEO_ID, "(?<=US)\\d+")) %>%
mutate(unique_id = paste0(census_year, "_", county_fips)) # "YEAR_FIPS"
full_censusdata %>%
write_csv(here("data/ACS_2009-2020_SelectedIndicators.csv"))
View(counties_only_all)
flattened_voting_as_wide <- voting_as_wide %>%
group_by(state,
state_po,
state_county,
county_name,
county_fips,
totalvotes) %>%
summarise(aggvotes_D = sum(DEMOCRAT, na.rm = TRUE),
aggvotes_R = sum(REPUBLICAN, na.rm = TRUE),
aggvotes_G = sum(GREEN, na.rm = TRUE),
aggvotes_L = sum(LIBERTARIAN, na.rm = TRUE),
aggvotes_O = sum(OTHER, na.rm = TRUE))
View(flattened_voting_as_wide)
flattened_voting_as_wide <- voting_as_wide %>%
group_by(year,
state,
state_po,
state_county,
county_name,
county_fips,
totalvotes) %>%
summarise(aggvotes_D = sum(DEMOCRAT, na.rm = TRUE),
aggvotes_R = sum(REPUBLICAN, na.rm = TRUE),
aggvotes_G = sum(GREEN, na.rm = TRUE),
aggvotes_L = sum(LIBERTARIAN, na.rm = TRUE),
aggvotes_O = sum(OTHER, na.rm = TRUE))
View(flattened_voting_as_wide)
flattened_voting_wide <- voting_as_wide %>%
group_by(year,
state,
state_po,
state_county,
county_name,
county_fips,
totalvotes) %>%
summarise(aggvotes_D = sum(DEMOCRAT, na.rm = TRUE),
aggvotes_R = sum(REPUBLICAN, na.rm = TRUE),
aggvotes_G = sum(GREEN, na.rm = TRUE),
aggvotes_L = sum(LIBERTARIAN, na.rm = TRUE),
aggvotes_O = sum(OTHER, na.rm = TRUE))
minvotes <- min(flattened_voting_wide$totalvotes)
maxvotes <- max(flattened_voting_wide$totalvotes)
flattened_voting_wide <- flattened_voting_wide %>%
mutate(
proportion_D = aggvotes_D / totalvotes,  # Democratic proportion
proportion_R = aggvotes_R / totalvotes,  # Republican proportion
proportion_explained_by_DR = proportion_D + proportion_R,
net_DR_margin = proportion_D - proportion_R)  # Net margin: positive = Dem, negative = Rep
View(flattened_voting_wide)
# set directory
here::i_am("code/cleaning_votingdata.R")
# Step 1 - load data ----------------------------------------------------------------------------------
countypres_raw <- read_csv(here("data/countypres_2000-2020.csv"))
# Step 2 - Make Dataset Wide --------------------------------------------------------------------
# making the dataset wide
voting_as_wide <- countypres_raw %>%
pivot_wider(names_from = party,
values_from = candidatevotes) %>%
mutate(state_county = paste0(state_po,
"-",
county_name)) %>% # retain only our identifier columns
filter(!(is.na(county_fips)))
# Connecticut - WRITE-IN
# Maine - Uniformed Service & Overseas
# Rhode Island - Federal Precinct
# Step 3 - Flatten dataset and calculate aggregates, proportions, margins--------------------------------------------------
flattened_voting_wide <- voting_as_wide %>%
group_by(year,
state,
state_po,
state_county,
county_name,
county_fips,
totalvotes) %>%
summarise(aggvotes_D = sum(DEMOCRAT, na.rm = TRUE),
aggvotes_R = sum(REPUBLICAN, na.rm = TRUE),
aggvotes_G = sum(GREEN, na.rm = TRUE),
aggvotes_L = sum(LIBERTARIAN, na.rm = TRUE),
aggvotes_O = sum(OTHER, na.rm = TRUE))
minvotes <- min(flattened_voting_wide$totalvotes)
maxvotes <- max(flattened_voting_wide$totalvotes)
flattened_voting_wide <- flattened_voting_wide %>%
mutate(
proportion_D = aggvotes_D / totalvotes,  # Democratic proportion
proportion_R = aggvotes_R / totalvotes,  # Republican proportion
proportion_explained_by_DR = proportion_D + proportion_R,
net_DR_margin = proportion_D - proportion_R)  # Net margin: positive = Dem, negative = Rep
View(flattened_voting_wide)
flattened_voting_wide <- voting_as_wide %>%
group_by(year,
state,
state_po,
state_county,
county_name,
county_fips,
totalvotes) %>%
summarise(aggvotes_D = sum(DEMOCRAT, na.rm = TRUE),
aggvotes_R = sum(REPUBLICAN, na.rm = TRUE),
aggvotes_G = sum(GREEN, na.rm = TRUE),
aggvotes_L = sum(LIBERTARIAN, na.rm = TRUE),
aggvotes_O = sum(OTHER, na.rm = TRUE))
minvotes <- min(flattened_voting_wide$totalvotes)
maxvotes <- max(flattened_voting_wide$totalvotes)
flattened_voting_wide <- flattened_voting_wide %>%
mutate(
proportion_D = aggvotes_D / totalvotes,  # Democratic proportion
proportion_R = aggvotes_R / totalvotes,  # Republican proportion
proportion_explained_by_DR = proportion_D + proportion_R,
net_DR_margin = proportion_D - proportion_R) %>% # Net margin: positive = Dem, negative = Rep
select(-state_county)
flattened_voting_wide <- voting_as_wide %>%
group_by(year,
state,
state_po,
state_county,
county_name,
county_fips,
totalvotes) %>%
summarise(aggvotes_D = sum(DEMOCRAT, na.rm = TRUE),
aggvotes_R = sum(REPUBLICAN, na.rm = TRUE),
aggvotes_G = sum(GREEN, na.rm = TRUE),
aggvotes_L = sum(LIBERTARIAN, na.rm = TRUE),
aggvotes_O = sum(OTHER, na.rm = TRUE))
minvotes <- min(flattened_voting_wide$totalvotes)
maxvotes <- max(flattened_voting_wide$totalvotes)
flattened_voting_wide <- flattened_voting_wide %>%
mutate(
proportion_D = aggvotes_D / totalvotes,  # Democratic proportion
proportion_R = aggvotes_R / totalvotes,  # Republican proportion
proportion_explained_by_DR = proportion_D + proportion_R,
net_DR_margin = proportion_D - proportion_R) # Net margin: positive = Dem, negative = Rep
flattened_voting_wide <- voting_as_wide %>%
group_by(year,
state,
state_po,
state_county,
county_name,
county_fips,
totalvotes) %>%
summarise(aggvotes_D = sum(DEMOCRAT, na.rm = TRUE),
aggvotes_R = sum(REPUBLICAN, na.rm = TRUE),
aggvotes_G = sum(GREEN, na.rm = TRUE),
aggvotes_L = sum(LIBERTARIAN, na.rm = TRUE),
aggvotes_O = sum(OTHER, na.rm = TRUE)) %>%
filter(county_fips != "2938000") %>% # remove Kansas City because jackson county already in dataset
# and this long fips is nonexistent in census dataset
# so it'll get dropped anyway
mutate(county_fips = str_pad(county_fips, width = 5, side = "left", pad = "0"))
View(flattened_voting_wide)
# set directory
here::i_am("code/cleaning_votingdata.R")
# Step 1 - load data ----------------------------------------------------------------------------------
countypres_raw <- read_csv(here("data/countypres_2000-2020.csv"))
# libraries -------------------------------------------------------------------
# loading
library(tidyverse)
library(here)
# set directory
here::i_am("code/cleaning_votingdata.R")
# Step 1 - load data ----------------------------------------------------------------------------------
countypres_raw <- read_csv(here("data/raw/countypres_2000-2020.csv"))
# Step 2 - Make Dataset Wide --------------------------------------------------------------------
# making the dataset wide
voting_as_wide <- countypres_raw %>%
pivot_wider(names_from = party,
values_from = candidatevotes) %>%
mutate(state_county = paste0(state_po,
"-",
county_name)) %>% # retain only our identifier columns
filter(!(is.na(county_fips)))
# Connecticut - WRITE-IN
# Maine - Uniformed Service & Overseas
# Rhode Island - Federal Precinct
# Step 3 - Flatten dataset and calculate aggregates, proportions, margins--------------------------------------------------
flattened_voting_wide <- voting_as_wide %>%
group_by(year,
state,
state_po,
state_county,
county_name,
county_fips,
totalvotes) %>%
summarise(aggvotes_D = sum(DEMOCRAT, na.rm = TRUE),
aggvotes_R = sum(REPUBLICAN, na.rm = TRUE),
aggvotes_G = sum(GREEN, na.rm = TRUE),
aggvotes_L = sum(LIBERTARIAN, na.rm = TRUE),
aggvotes_O = sum(OTHER, na.rm = TRUE)) %>%
filter(county_fips != "2938000") %>% # remove Kansas City because jackson county already in dataset
# and this long fips is nonexistent in census dataset
# so it'll get dropped anyway
mutate(county_fips = str_pad(county_fips, width = 5, side = "left", pad = "0"))
minvotes <- min(flattened_voting_wide$totalvotes)
maxvotes <- max(flattened_voting_wide$totalvotes)
flattened_voting_wide <- flattened_voting_wide %>%
mutate(
proportion_D = aggvotes_D / totalvotes,  # Democratic proportion
proportion_R = aggvotes_R / totalvotes,  # Republican proportion
proportion_explained_by_DR = proportion_D + proportion_R,
net_DR_margin = proportion_D - proportion_R) %>% # Net margin: positive = Dem, negative = Rep
flattened_voting_wide %>%
write_csv(here("data/clean/CountyPresReturns_2000-2020_Flattened.csv"))
flattened_voting_wide <- voting_as_wide %>%
group_by(year,
state,
state_po,
state_county,
county_name,
county_fips,
totalvotes) %>%
summarise(aggvotes_D = sum(DEMOCRAT, na.rm = TRUE),
aggvotes_R = sum(REPUBLICAN, na.rm = TRUE),
aggvotes_G = sum(GREEN, na.rm = TRUE),
aggvotes_L = sum(LIBERTARIAN, na.rm = TRUE),
aggvotes_O = sum(OTHER, na.rm = TRUE)) %>%
filter(county_fips != "2938000") %>% # remove Kansas City because jackson county already in dataset
# and this long fips is nonexistent in census dataset
# so it'll get dropped anyway
mutate(county_fips = str_pad(county_fips, width = 5, side = "left", pad = "0"))
minvotes <- min(flattened_voting_wide$totalvotes)
maxvotes <- max(flattened_voting_wide$totalvotes)
flattened_voting_wide <- flattened_voting_wide %>%
mutate(
proportion_D = aggvotes_D / totalvotes,  # Democratic proportion
proportion_R = aggvotes_R / totalvotes,  # Republican proportion
proportion_explained_by_DR = proportion_D + proportion_R,
net_DR_margin = proportion_D - proportion_R) # Net margin: positive = Dem, negative = Rep
flattened_voting_wide %>%
write_csv(here("data/clean/CountyPresReturns_2000-2020_Flattened.csv"))
flattened_voting_wide <- voting_as_wide %>%
group_by(year,
state,
state_po,
state_county,
county_name,
county_fips,
totalvotes) %>%
summarise(aggvotes_D = sum(DEMOCRAT, na.rm = TRUE),
aggvotes_R = sum(REPUBLICAN, na.rm = TRUE),
aggvotes_G = sum(GREEN, na.rm = TRUE),
aggvotes_L = sum(LIBERTARIAN, na.rm = TRUE),
aggvotes_O = sum(OTHER, na.rm = TRUE)) %>%
filter(county_fips != "2938000") %>% # remove Kansas City because jackson county already in dataset
# and this long fips is nonexistent in census dataset
# so it'll get dropped anyway
mutate(county_fips = str_pad(county_fips, width = 5, side = "left", pad = "0"))
minvotes <- min(flattened_voting_wide$totalvotes)
maxvotes <- max(flattened_voting_wide$totalvotes)
flattened_voting_wide <- flattened_voting_wide %>%
mutate(unique_id = paste0(year, "_", county_fips)) %>%
mutate(
proportion_D = aggvotes_D / totalvotes,  # Democratic proportion
proportion_R = aggvotes_R / totalvotes,  # Republican proportion
proportion_explained_by_DR = proportion_D + proportion_R,
net_DR_margin = proportion_D - proportion_R) # Net margin: positive = Dem, negative = Rep
flattened_voting_wide %>%
write_csv(here("data/clean/CountyPresReturns_2000-2020_Flattened.csv"))
# loading
library(tidyverse)
library(here)
# set directory
here::i_am("code/finalizing_data.R")
# Step 1 - load data ----------------------------------------
clean_voting <- read_csv(here("data/clean/CountyPresReturns_2000-2020_Flattened.csv"))
clean_census <- read_csv(here("data/clean/ACS_2009-2020_SelectedIndicators.csv"))
pipeline_ready <- clean_voting %>%
inner_join(clean_census, by = unique_id)
pipeline_ready <- clean_voting %>%
inner_join(clean_census, by = "unique_id")
View(pipeline_ready)
View(clean_census)
View(clean_voting)
# Step 1 - load data -------------------------------------------------------------------
clean_voting <- read_csv(here("data/clean/CountyPresReturns_2000-2020_Flattened.csv")) %>%
select(-state,
-state_county)
clean_census <- read_csv(here("data/clean/ACS_2009-2020_SelectedIndicators.csv")) %>%
select(-county_fips,
-census_year)
# Step 2 - join data --------------------------------------------------------------------
pipeline_ready <- clean_voting %>%
inner_join(clean_census, by = "unique_id")
# Step 3 - Assess missing values ---------------------------------------------------------
na_counts <- pipeline_ready %>%
summarise(across(everything(), ~ sum(is.na(.)), .names = "NA_count_{.col}")) %>%
pivot_longer(everything(), names_to = "Column", values_to = "NA_Count") %>%
filter(NA_Count > 0) %>%
arrange(desc(NA_Count))
View(na_counts)
print(na_counts)
na_counts <- pipeline_ready %>%
summarise(across(everything(), ~ sum(is.na(.)), .names = "NA_count_{.col}")) %>%
pivot_longer(everything(), names_to = "Column", values_to = "NA_Count") %>%
filter(NA_Count > 0) %>%
arrange(desc(NA_Count))
na_counts <- pipeline_ready %>%
summarise(across(everything(), ~ sum(is.na(.)), .names = "NA_count_{.col}")) %>%
pivot_longer(everything(), names_to = "Column", values_to = "NA_Count") %>%
filter(NA_Count > 0) %>%
arrange(desc(NA_Count))
print(na_counts)
na_counts <- pipeline_ready %>%
summarise(across(everything(), ~ sum(is.na(.)), .names = "NA_count_{.col}")) %>%
pivot_longer(everything(), names_to = "Column", values_to = "NA_Count") %>%
#filter(NA_Count > 0) %>%
arrange(desc(NA_Count))
View(na_counts)
pipeline_ready %>%
write_csv(here("data/clean/Combined_Voting&Census_2008-2020.csv"))
# libraries -------------------------------------------------------------------
# loading
library(tidyverse)
library(here)
# set directory
here::i_am("code/cleaning_censusdata.R")
# Step 1 - load data ----------------------------------------------------------------------------------
# CENSUS DATASETS
# Specify the folder path where the CSV files are located
folder_path <- paste0(here("data/raw/api_censusdata"))
# Get all file names in the folder that match the CSV format
file_list <- list.files(path = folder_path, full.names = TRUE)
# Load each file and dynamically name each dataframe
for (file in file_list) {
# Extract the file name without the path and extension
file_name <- basename(file)
# Create a variable name by removing "group(" and ").csv"
var_name <- str_remove_all(file_name, "\\.csv")
# Assign the data to a variable with the dynamically created name
assign(var_name, read_csv(file))}
# Step 2 - Drop Irrelevant Columns ----------------------------------------------------------------------
# Get a list of all dataframe names in the environment that match your naming convention
dataframe_names <- ls(pattern = "^DP\\d{2}_\\d{4}")
# Define a function to drop columns that start with "DP" but do not end with "PE"
drop_nonPE_cols <- function(df) {
df %>%
select(contains("PE") | matches("^GEO_ID$")) %>% # this also drops state (num), county (num), name (string)
select(-contains("PEA")) %>%
select(where(~ !any(. == "(X)", na.rm = TRUE))) %>%
select(where(~ !any(. == "-888888888", na.rm = TRUE)))
}
# Apply the function to each dataframe in the environment and update them
for (name in dataframe_names) {
assign(name, drop_nonPE_cols(get(name)))
}
# Step 3 -  Join DPs by year together ----------------------------------------------------
census_2009 <- DP02_2009 %>%
inner_join(DP03_2009, by = "GEO_ID") %>%
inner_join(DP04_2009, by = "GEO_ID") %>%
inner_join(DP05_2009, by = "GEO_ID") %>%
mutate(census_year = "2008")
census_2012 <- DP02_2012 %>%
inner_join(DP03_2012, by = "GEO_ID") %>%
inner_join(DP04_2012, by = "GEO_ID") %>%
inner_join(DP05_2012, by = "GEO_ID") %>%
mutate(census_year = "2012")
census_2016 <- DP02_2016 %>%
inner_join(DP03_2016, by = "GEO_ID") %>%
inner_join(DP04_2016, by = "GEO_ID") %>%
inner_join(DP05_2016, by = "GEO_ID") %>%
mutate(census_year = "2016")
census_2020 <- DP02_2020 %>%
inner_join(DP03_2020, by = "GEO_ID") %>%
inner_join(DP04_2020, by = "GEO_ID") %>%
inner_join(DP05_2020, by = "GEO_ID") %>%
mutate(census_year = "2020")
# Step 4 - drop all year dfs to lowest common denominator of columns ----------------------
# Step 1: Identify common columns
common_columns <- Reduce(intersect, list(names(census_2009),
names(census_2012),
names(census_2016),
names(census_2020)))
# Step 2: Subset each dataset by the common columns
# subsetting by our list means they will all be in same order
# which means we can rbind afterwards without issue
LCD_census_2009 <- census_2009[ , common_columns]
LCD_census_2012 <- census_2012[ , common_columns]
LCD_census_2016 <- census_2016[ , common_columns]
LCD_census_2020 <- census_2020[ , common_columns]
# Step 3: Row-bind the datasets
full_censusdata <- do.call(rbind, list(LCD_census_2009,
LCD_census_2012,
LCD_census_2016,
LCD_census_2020))
# MAYBE: NEED TO DROP ALSO ANY FIPS THAT ARE NOT IN EVERY YEAR?
# fuuuuuuuuuuuuuck
# skip this for now
# step 5 - prep for join with voting data ------------------------------------------------
full_censusdata <- full_censusdata %>%
mutate(county_fips = str_extract(GEO_ID, "(?<=US)\\d+")) %>%
mutate(unique_id = paste0(census_year, "_", county_fips)) # "YEAR_FIPS"
View(full_censusdata)
full_censusdata$census_year<-as.character(full_censusdata$census_year)
full_censusdata$county_fips<-as.character(full_censusdata$county_fips)
aa_experiment <- full_censusdata %>%
select(-where(~ all(. >= 101, na.rm = TRUE)))
View(aa_experiment)
aa_experiment <- full_censusdata %>%
#select(-where(~ all(. >= 101, na.rm = TRUE)))
select(-where(~ !any(. > 101, na.rm = TRUE)))
View(aa_experiment)
aa_experiment <- full_censusdata %>%
#select(-where(~ all(. >= 101, na.rm = TRUE)))
select(where(~ !any(. > 101, na.rm = TRUE)))
View(aa_experiment)
full_censusdata_slim %>%
write_csv(here("data/clean/ACS_2009-2020_SelectedIndicators_Slim.csv"))
full_censusdata$census_year<-as.character(full_censusdata$census_year)
full_censusdata$county_fips<-as.character(full_censusdata$county_fips)
full_censusdata_slim <- full_censusdata %>%
#select(-where(~ all(. >= 101, na.rm = TRUE)))
select(where(~ !any(. > 101, na.rm = TRUE)))
full_censusdata_slim %>%
write_csv(here("data/clean/ACS_2009-2020_SelectedIndicators_Slim.csv"))
